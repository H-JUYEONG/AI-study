"""
 * The Tag2Text Model
 * Written by Xinyu Huang
"""

# STEP 1 : Import modules
import argparse
import numpy as np
import random
import torch
from PIL import Image
from ram.models import tag2text
from ram import inference_tag2text as inference
from ram import get_transform

# STEP 2 : Configuration and model setup
device = torch.device(
    "cuda" if torch.cuda.is_available() else "cpu"
)  # Check device (GPU or CPU)

# Model and image configurations
model_path = "tag2text_swin_14m.pth"  # Path to the pretrained model
image_path = "test.jpg"  # Path to the input image
image_size = 384  # Input image size
thre = 0.68  # Threshold for tagging confidence
specified_tags = ""  # User-specified tags (optional)

# Transform configuration
transform = get_transform(image_size=image_size)

# Tags to delete for cleaner captioning
# 127: "quarter"; 2961: "back", 3351: "two"; 3265: "three"; 3338: "four"; 3355: "five"; 3359: "one"
delete_tag_index = [127, 2961, 3351, 3265, 3338, 3355, 3359]

# Load the model
model = tag2text(
    pretrained=model_path,
    image_size=image_size,
    vit="swin_b",
    delete_tag_index=delete_tag_index,
)
model.threshold = thre  # Set tagging threshold
model.eval()
model = model.to(device)  # Move the model to the appropriate device (GPU or CPU)

# STEP 3 : Load and preprocess image
image = (
    transform(Image.open(image_path)).unsqueeze(0).to(device)
)  # Preprocess image and move to device

# STEP 4 : Perform inference
res = inference(image, model, specified_tags)

# STEP 5 : Post-processing and results
print("Model Identified Tags: ", res[0])  # Tags identified by the model
print("User Specified Tags: ", res[1])  # Tags specified by the user (if any)
print("Image Caption: ", res[2])  # Caption generated by the model